//! Regression Testing Framework
//!
//! Framework for detecting behavioral regressions by comparing current CLI output
//! against known-good baseline outputs (golden master testing).

use anyhow::Result;
use serde::{Deserialize, Serialize};
use std::path::PathBuf;
use tempfile::TempDir;

mod in_process_test_utils;
mod test_utils;
use in_process_test_utils::CapturedOutput;
use test_utils::setup_git_repo;

/// Represents expected output for a CLI command
#[derive(Serialize, Deserialize, Debug, Clone)]
pub struct ExpectedOutput {
    /// Command arguments to execute
    pub command: Vec<String>,
    /// Expected exit code
    pub expected_exit_code: i32,
    /// Strings that must be present in stdout
    pub expected_stdout_contains: Vec<String>,
    /// Strings that must be present in stderr  
    pub expected_stderr_contains: Vec<String>,
    /// Strings that must NOT be present in stdout
    pub expected_stdout_not_contains: Vec<String>,
    /// Strings that must NOT be present in stderr
    pub expected_stderr_not_contains: Vec<String>,
    /// Description of what this test validates
    pub description: String,
    /// Whether this test requires specific setup
    pub requires_setup: bool,
}

/// Regression test suite configuration
#[derive(Serialize, Deserialize, Debug)]
pub struct RegressionTestSuite {
    /// Version of the test suite format
    pub version: String,
    /// Description of this test suite
    pub description: String,
    /// List of test cases
    pub test_cases: Vec<ExpectedOutput>,
}

impl RegressionTestSuite {
    /// Create a new regression test suite with baseline behaviors
    pub fn create_baseline_suite() -> Self {
        let test_cases = vec![
            // Help and version commands (should be stable)
            ExpectedOutput {
                command: vec!["--help".to_string()],
                expected_exit_code: 0,
                expected_stdout_contains: vec![
                    "Usage:".to_string(),
                    "Commands".to_string(),
                    "Options".to_string(),
                    "issue".to_string(),
                ],
                expected_stderr_contains: vec![],
                expected_stdout_not_contains: vec!["Error".to_string(), "panic".to_string()],
                expected_stderr_not_contains: vec!["Error".to_string(), "panic".to_string()],
                description: "Help command shows expected sections and commands".to_string(),
                requires_setup: false,
            },
            ExpectedOutput {
                command: vec!["--version".to_string()],
                expected_exit_code: 0,
                expected_stdout_contains: vec!["swissarmyhammer".to_string()],
                expected_stderr_contains: vec![],
                expected_stdout_not_contains: vec!["Error".to_string()],
                expected_stderr_not_contains: vec!["Error".to_string()],
                description: "Version command shows application name".to_string(),
                requires_setup: false,
            },
            // Issue command help
            ExpectedOutput {
                command: vec!["issue".to_string(), "--help".to_string()],
                expected_exit_code: 0,
                expected_stdout_contains: vec![
                    "ISSUE management commands".to_string(),
                    "create".to_string(),
                    "list".to_string(),
                    "show".to_string(),
                    "update".to_string(),
                    "complete".to_string(),
                    "work".to_string(),
                ],
                expected_stderr_contains: vec![],
                expected_stdout_not_contains: vec!["Error".to_string()],
                expected_stderr_not_contains: vec!["Error".to_string()],
                description: "Issue help shows all major subcommands".to_string(),
                requires_setup: false,
            },
            // Search command available via dynamic CLI
            ExpectedOutput {
                command: vec!["search".to_string(), "--help".to_string()],
                expected_exit_code: 0,
                expected_stdout_contains: vec![
                    "SEARCH management commands".to_string(),
                    "index".to_string(),
                    "query".to_string(),
                ],
                expected_stderr_contains: vec![],
                expected_stdout_not_contains: vec!["Error".to_string()],
                expected_stderr_not_contains: vec!["Error".to_string()],
                description: "Search commands available via dynamic CLI".to_string(),
                requires_setup: false,
            },
            // Error cases (consistent error behavior)
            ExpectedOutput {
                command: vec!["invalid".to_string(), "command".to_string()],
                expected_exit_code: 2,
                expected_stdout_contains: vec![],
                expected_stderr_contains: vec!["error".to_string()],
                expected_stdout_not_contains: vec![],
                expected_stderr_not_contains: vec!["panic".to_string()],
                description: "Invalid commands produce appropriate error messages".to_string(),
                requires_setup: false,
            },
            // Issue operations with setup
            ExpectedOutput {
                command: vec!["issue".to_string(), "list".to_string()],
                expected_exit_code: 0,
                expected_stdout_contains: vec![],
                expected_stderr_contains: vec![],
                expected_stdout_not_contains: vec!["Error".to_string(), "panic".to_string()],
                expected_stderr_not_contains: vec!["panic".to_string()],
                description: "Issue list command completes successfully".to_string(),
                requires_setup: true,
            },
            // Error cases with setup
            ExpectedOutput {
                command: vec![
                    "issue".to_string(),
                    "show".to_string(),
                    "--name".to_string(),
                    "nonexistent".to_string(),
                ],
                expected_exit_code: 1,
                expected_stdout_contains: vec![],
                expected_stderr_contains: vec!["error".to_string()],
                expected_stdout_not_contains: vec!["panic".to_string()],
                expected_stderr_not_contains: vec!["panic".to_string()],
                description: "Non-existent issue produces appropriate error".to_string(),
                requires_setup: true,
            },
        ];

        Self {
            version: "1.0.0".to_string(),
            description: "Baseline regression test suite for CLI-MCP integration".to_string(),
            test_cases,
        }
    }

    /// Save the test suite to a file
    pub fn save_to_file(&self, path: &PathBuf) -> Result<()> {
        let content = serde_yaml::to_string(self)?;
        std::fs::write(path, content)?;
        Ok(())
    }

    /// Load test suite from a file
    pub fn load_from_file(path: &PathBuf) -> Result<Self> {
        let content = std::fs::read_to_string(path)?;
        let suite: Self = serde_yaml::from_str(&content)?;
        Ok(suite)
    }

    /// Execute all test cases and return results
    pub async fn execute_all_tests(
        &self,
        working_dir: Option<&PathBuf>,
    ) -> Vec<RegressionTestResult> {
        let mut results = Vec::new();
        for test_case in &self.test_cases {
            results.push(self.execute_single_test(test_case, working_dir).await);
        }
        results
    }

    /// Execute a single test case
    pub async fn execute_single_test(
        &self,
        test_case: &ExpectedOutput,
        working_dir: Option<&PathBuf>,
    ) -> RegressionTestResult {
        // Save current directory
        let original_dir = std::env::current_dir().unwrap_or_else(|_| PathBuf::from("."));

        // Change to working directory if specified
        if let Some(dir) = working_dir {
            if let Err(e) = std::env::set_current_dir(dir) {
                return RegressionTestResult {
                    test_case: test_case.clone(),
                    passed: false,
                    actual_exit_code: None,
                    actual_stdout: String::new(),
                    actual_stderr: String::new(),
                    failure_reason: Some(format!("Failed to change directory: {e}")),
                };
            }
        }

        // For regression testing, always use subprocess to test actual CLI behavior
        let result = self
            .execute_command_subprocess(&test_case.command, working_dir)
            .await;

        // Restore original directory
        let _ = std::env::set_current_dir(original_dir);

        let (actual_exit_code, actual_stdout, actual_stderr) = match result {
            Ok(output) => (output.exit_code, output.stdout, output.stderr),
            Err(e) => {
                return RegressionTestResult {
                    test_case: test_case.clone(),
                    passed: false,
                    actual_exit_code: None,
                    actual_stdout: String::new(),
                    actual_stderr: String::new(),
                    failure_reason: Some(format!("Failed to execute command: {e}")),
                };
            }
        };

        let mut failure_reasons = vec![];

        // Check exit code
        if actual_exit_code != test_case.expected_exit_code {
            failure_reasons.push(format!(
                "Exit code mismatch: expected {}, got {}",
                test_case.expected_exit_code, actual_exit_code
            ));
        }

        // Check stdout contains
        for expected in &test_case.expected_stdout_contains {
            if !actual_stdout.contains(expected) {
                failure_reasons.push(format!("Stdout missing expected content: '{expected}'"));
            }
        }

        // Check stderr contains
        for expected in &test_case.expected_stderr_contains {
            if !actual_stderr.contains(expected) {
                failure_reasons.push(format!("Stderr missing expected content: '{expected}'"));
            }
        }

        // Check stdout does not contain
        for not_expected in &test_case.expected_stdout_not_contains {
            if actual_stdout.contains(not_expected) {
                failure_reasons.push(format!(
                    "Stdout contains forbidden content: '{not_expected}'"
                ));
            }
        }

        // Check stderr does not contain
        for not_expected in &test_case.expected_stderr_not_contains {
            if actual_stderr.contains(not_expected) {
                failure_reasons.push(format!(
                    "Stderr contains forbidden content: '{not_expected}'"
                ));
            }
        }

        RegressionTestResult {
            test_case: test_case.clone(),
            passed: failure_reasons.is_empty(),
            actual_exit_code: Some(actual_exit_code),
            actual_stdout,
            actual_stderr,
            failure_reason: if failure_reasons.is_empty() {
                None
            } else {
                Some(failure_reasons.join("; "))
            },
        }
    }

    /// Execute command using subprocess for consistent regression testing
    async fn execute_command_subprocess(
        &self,
        command: &[String],
        _working_dir: Option<&PathBuf>,
    ) -> Result<CapturedOutput> {
        use tokio::time::{timeout, Duration};

        // Find the actual sah executable in target/debug/deps/
        let binary_path = if let Ok(path) = std::env::var("CARGO_BIN_EXE_sah") {
            path
        } else {
            // Fallback: find the sah executable in deps directory
            let base_dir = env!("CARGO_MANIFEST_DIR").replace("/swissarmyhammer-cli", "");
            let deps_dir = format!("{}/target/debug/deps", base_dir);

            match std::fs::read_dir(&deps_dir) {
                Ok(entries) => {
                    let mut sah_exe = None;
                    for entry in entries.flatten() {
                        let path = entry.path();
                        if let Some(filename) = path.file_name().and_then(|n| n.to_str()) {
                            if filename.starts_with("sah-") && !filename.contains('.') {
                                // Check if it's executable by trying to get metadata
                                if let Ok(metadata) = std::fs::metadata(&path) {
                                    // On Unix, check if it has execute permissions
                                    #[cfg(unix)]
                                    {
                                        use std::os::unix::fs::PermissionsExt;
                                        if metadata.permissions().mode() & 0o111 != 0 {
                                            sah_exe = Some(path);
                                            break;
                                        }
                                    }
                                    // On Windows, any file in deps is potentially executable
                                    #[cfg(windows)]
                                    {
                                        sah_exe = Some(path);
                                        break;
                                    }
                                }
                            }
                        }
                    }
                    sah_exe
                        .map(|p| p.to_string_lossy().to_string())
                        .unwrap_or_else(|| format!("{}/target/debug/sah", base_dir))
                }
                Err(_) => format!("{}/target/debug/sah", base_dir),
            }
        };

        let command_future = async {
            eprintln!("DEBUG: Trying to execute binary at: {}", binary_path);
            let output = tokio::process::Command::new(&binary_path)
                .args(command)
                .current_dir(std::env::current_dir().unwrap())
                .kill_on_drop(true)
                .output()
                .await
                .map_err(|e| anyhow::anyhow!("Failed to execute subprocess: {}", e))?;

            Ok::<_, anyhow::Error>(CapturedOutput {
                stdout: String::from_utf8_lossy(&output.stdout).to_string(),
                stderr: String::from_utf8_lossy(&output.stderr).to_string(),
                exit_code: output.status.code().unwrap_or(1),
            })
        };

        match timeout(Duration::from_secs(60), command_future).await {
            Ok(result) => result,
            Err(_) => Ok(CapturedOutput {
                stdout: String::new(),
                stderr: "Test command timed out after 60 seconds".to_string(),
                exit_code: 124,
            }),
        }
    }
}

/// Result of executing a regression test
#[derive(Debug, Clone)]
pub struct RegressionTestResult {
    pub test_case: ExpectedOutput,
    pub passed: bool,
    pub actual_exit_code: Option<i32>,
    pub actual_stdout: String,
    pub actual_stderr: String,
    pub failure_reason: Option<String>,
}

/// Regression test report
#[derive(Debug)]
pub struct RegressionTestReport {
    pub total_tests: usize,
    pub passed_tests: usize,
    pub failed_tests: usize,
    pub results: Vec<RegressionTestResult>,
}

impl RegressionTestReport {
    pub fn from_results(results: Vec<RegressionTestResult>) -> Self {
        let total_tests = results.len();
        let passed_tests = results.iter().filter(|r| r.passed).count();
        let failed_tests = total_tests - passed_tests;

        Self {
            total_tests,
            passed_tests,
            failed_tests,
            results,
        }
    }

    pub fn print_summary(&self) {
        println!("Regression Test Report");
        println!("=====================");
        println!("Total tests: {}", self.total_tests);
        println!("Passed: {}", self.passed_tests);
        println!("Failed: {}", self.failed_tests);
        println!(
            "Success rate: {:.1}%",
            (self.passed_tests as f64 / self.total_tests as f64) * 100.0
        );

        if self.failed_tests > 0 {
            println!("\nFailed Tests:");
            println!("=============");
            for result in &self.results {
                if !result.passed {
                    println!("❌ {}", result.test_case.description);
                    println!(
                        "   Command: swissarmyhammer {}",
                        result.test_case.command.join(" ")
                    );
                    if let Some(reason) = &result.failure_reason {
                        println!("   Reason: {reason}");
                    }
                    println!();
                }
            }
        }
    }

    pub fn save_detailed_report(&self, path: &PathBuf) -> Result<()> {
        let mut report = String::new();
        report.push_str("# Regression Test Detailed Report\n\n");
        report.push_str(&format!("**Total tests:** {}\n", self.total_tests));
        report.push_str(&format!("**Passed:** {}\n", self.passed_tests));
        report.push_str(&format!("**Failed:** {}\n", self.failed_tests));
        report.push_str(&format!(
            "**Success rate:** {:.1}%\n\n",
            (self.passed_tests as f64 / self.total_tests as f64) * 100.0
        ));

        for result in &self.results {
            let status = if result.passed {
                "✅ PASS"
            } else {
                "❌ FAIL"
            };
            report.push_str(&format!(
                "## {} {}\n\n",
                status, result.test_case.description
            ));
            report.push_str(&format!(
                "**Command:** `swissarmyhammer {}`\n\n",
                result.test_case.command.join(" ")
            ));

            if let Some(exit_code) = result.actual_exit_code {
                report.push_str(&format!(
                    "**Exit code:** {} (expected: {})\n\n",
                    exit_code, result.test_case.expected_exit_code
                ));
            }

            if !result.passed {
                if let Some(reason) = &result.failure_reason {
                    report.push_str(&format!("**Failure reason:** {reason}\n\n"));
                }
            }

            if !result.actual_stdout.is_empty() {
                report.push_str("**Actual stdout:**\n```\n");
                report.push_str(&result.actual_stdout);
                report.push_str("\n```\n\n");
            }

            if !result.actual_stderr.is_empty() {
                report.push_str("**Actual stderr:**\n```\n");
                report.push_str(&result.actual_stderr);
                report.push_str("\n```\n\n");
            }

            report.push_str("---\n\n");
        }

        std::fs::write(path, report)?;
        Ok(())
    }
}

/// Setup function for regression testing
fn setup_regression_test_environment() -> Result<(TempDir, PathBuf)> {
    let temp_dir = TempDir::new()?;
    let temp_path = temp_dir.path().to_path_buf();

    // Create basic directory structure
    let issues_dir = temp_path.join("issues");
    std::fs::create_dir_all(&issues_dir)?;

    let swissarmyhammer_dir = temp_path.join(".swissarmyhammer");
    std::fs::create_dir_all(&swissarmyhammer_dir)?;

    setup_git_repo(&temp_path)?;

    Ok((temp_dir, temp_path))
}

/// Test the regression testing framework itself
#[ignore = "Disabled pending CLI validation fix"]
#[tokio::test]
async fn test_regression_framework() -> Result<()> {
    let (_temp_dir, temp_path) = setup_regression_test_environment()?;

    // Create and execute baseline test suite
    let suite = RegressionTestSuite::create_baseline_suite();
    let results = suite.execute_all_tests(Some(&temp_path)).await;
    let report = RegressionTestReport::from_results(results);

    // The framework should work
    assert!(report.total_tests > 0, "Should have test cases");

    // Save detailed report for debugging
    let debug_report_path = temp_path.join("regression_debug_report.md");
    let _ = report.save_detailed_report(&debug_report_path);

    // Print report for debugging before assertion
    report.print_summary();

    // Most baseline tests should pass (allowing for some environment differences)
    let success_rate = report.passed_tests as f64 / report.total_tests as f64;
    assert!(
        success_rate > 0.6, // At least 60% should pass (adjusted after memo commands migration)
        "Success rate too low: {:.1}% ({}/{})",
        success_rate * 100.0,
        report.passed_tests,
        report.total_tests
    );

    Ok(())
}

/// Test saving and loading test suites
#[test]
fn test_suite_serialization() -> Result<()> {
    let temp_dir = TempDir::new()?;
    let suite_path = temp_dir.path().join("test_suite.yaml");

    // Create and save suite
    let original_suite = RegressionTestSuite::create_baseline_suite();
    original_suite.save_to_file(&suite_path)?;

    // Load suite
    let loaded_suite = RegressionTestSuite::load_from_file(&suite_path)?;

    // Should be equivalent
    assert_eq!(original_suite.version, loaded_suite.version);
    assert_eq!(original_suite.description, loaded_suite.description);
    assert_eq!(
        original_suite.test_cases.len(),
        loaded_suite.test_cases.len()
    );

    Ok(())
}

/// Test creating custom regression test suite
#[tokio::test]
async fn test_custom_regression_suite() -> Result<()> {
    let (_temp_dir, temp_path) = setup_regression_test_environment()?;

    // Create custom test suite focused on specific behaviors
    let custom_suite = RegressionTestSuite {
        version: "1.0.0".to_string(),
        description: "Custom CLI behavior validation suite".to_string(),
        test_cases: vec![
            ExpectedOutput {
                command: vec![
                    "issue".to_string(),
                    "list".to_string(),
                    "--format".to_string(),
                    "json".to_string(),
                ],
                expected_exit_code: 0,
                expected_stdout_contains: vec![], // May be empty, that's ok
                expected_stderr_contains: vec![],
                expected_stdout_not_contains: vec!["Error".to_string(), "panic".to_string()],
                expected_stderr_not_contains: vec!["panic".to_string()],
                description: "Issue list JSON format produces valid output".to_string(),
                requires_setup: true,
            },
            ExpectedOutput {
                command: vec!["memo".to_string(), "create".to_string()],
                expected_exit_code: 2, // Should fail due to missing required argument
                expected_stdout_contains: vec![],
                expected_stderr_contains: vec!["required".to_string()],
                expected_stdout_not_contains: vec!["panic".to_string()],
                expected_stderr_not_contains: vec!["panic".to_string()],
                description: "Memo create without title produces appropriate error".to_string(),
                requires_setup: true,
            },
        ],
    };

    let results = custom_suite.execute_all_tests(Some(&temp_path)).await;
    let report = RegressionTestReport::from_results(results);

    assert_eq!(report.total_tests, 2);
    // At least one should pass
    assert!(
        report.passed_tests >= 1,
        "At least one custom test should pass"
    );

    Ok(())
}
